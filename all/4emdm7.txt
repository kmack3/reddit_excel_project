slow
4emdm7
Data tables are slow

Is there any way to speed up data table processing?

When I have to delete data table rows, excel processes this extremely slow. I have tried turning auto calculate off, but it doesn't seem to help.

Anyone have any ideas?

Thanks!


-------------
What version of Excel? How many rows of data? Columns? Columns with formulas? Does it run slow on any other machine?
-------------
Can you delete the entire row, not just the data table row?
If you select a few tables lines to delete, the excel process deletes them one at a time.
But if you select entire sheet rows, excel will delete them all at once. I don't know why this is, but it makes deleting an entire sheet row faster than deleting table rows.
-------------
Do you have any volatile formulas in your table (i.e., offset()).  This is a problem I ran into the other day.  I ran the vba macros on this site https://msdn.microsoft.com/en-us/library/office/ff521867(v=office.14).aspx.  They might work on your version to find what is the specific range that is slowing down the calculations.  I changed my formulas based on inputs from this r/ and all is good.
-------------
Can you share how your setup looks and how you're deleting it? If you're using for loops in any kind of mass delete there's probably a better way. 
-------------
Version 2016. One row takes a few seconds. Sometimes I am deleting hundreds.

No formulas on these, just raw data stored in table.

Have not tested on another machine. This is work related on my laptop here at the office, I technically COULD test it on my home machine, but have not.
-------------
Just tested this out. 

Looks like it takes just as long.
-------------
All of the formulas were set up to reference a data table and be absolute. The sheet that calls the information from the source sheet is a dynamic sheet that grows one line every day. Each row = 1 day and each every three columns is grouped. There are about 48 columns and 1 row per day from about February 2015 to today.

I set it up with tables so I could just call the table columns and have it a little more organized.

Seemed like the best idea at the time, but now that the data is so much bigger, it's taking much longer than anticipated.

-------------
I'm running a macro to find lines that do NOT equal 2 different criteria and delete those lines. I wrote the code pretty quickly to get the job done so i wouldn't have to go through all of the data line by line.

Unsure how to make the code more efficient.

-------------
Are there any other tabs? when you delete a row do you get the calculating message on the bottom?

If you hit CTRL+END what row does it take you down to?
-------------
Can you post it?
-------------
It takes me to the end of my data. 

I just tested this on a clean workbook with all of this data but no other tabs. The information on this sheet is all stored as value and doesnt reference any other sheets, however I had 2 other sheets pulling data from this tab. 

The test on the other workbook was much faster. I think having other tabs referencing this information is causing it to slow down. 

I think my next problem is figuring out how to delete the rows I need to get rid faster. 


-------------
Kinda messy, but here is the code. I don't remember the last time I made any changes to it. I'm sure there's better way to write what i'm doing, but I think that /u/tjen has the right idea as to why the workbook is so slow. 

    Option Explicit
    Public Sub GetLastRC(MaxCol, MaxRow)
        MaxCol = Cells(1, Columns.Count).End(xlToLeft).Column
        MaxRow = Cells(Rows.Count, "A").End(xlUp).Row
    End Sub
    
    
    Private Sub CleanUp_Click()
    Application.ScreenUpdating = False
    Application.Calculation = xlCalculationManual
    
    
    Dim Acc As String
    Dim MaxCol As Integer
    Dim MaxRow As Integer
    Dim i As Integer
    Dim LastUpdate As Integer
    Dim x As Integer
    
    '1212020000
    '6110000000
    
    Call GetLastRC(MaxCol, MaxRow) 'Get the last row in data after pasting to sheet
    LastUpdate = Range("F1") 'The last known last row is stored as LastUpdate
    
    For i = LastUpdate To MaxRow 'Loop through all rows from the last update to current last row
         Acc = Cells(i, 3)
         If Left(Acc, 7) = 1212020 Or Left(Acc, 7) = 6110000 Then 'These are the two criteria I want to keep, otherwise delete the entire row
              GoTo 1:
         Else
              If i > MaxRow Then 'if current row is above max row, set a new value for the last updated row and turn on screen updating and calculations again
                   Range("F1") = MaxRow
                   Application.ScreenUpdating = True
                   Application.Calculation = xlCalculationAutomatic
                   End
              Else
              Cells(i, 3).Select
                   Selection.EntireRow.Delete xlShiftUp 'deletes row of unwanted data and shift data up
                   MaxRow = MaxRow - 1 'current row data is now shifted back up one row
                   i = i - 1
              End If
         End If
    
    
    
    1:     'next row if data is what I want to keep
    Next i
    Application.Calculation = xlCalculationAutomatic
    Range("F1") = i
    
    Application.Calculation = xlCalculationAutomatic
    Application.ScreenUpdating = True
    
    End Sub

-------------
When you delete your data, the cells in the other sheets that reference it will need to recalculate. If you have a large number of formulas, this is most definitely what slows down your calculation.

It may be possible to make your two other sheets reference the data more efficiently, but otherwise you're stuck doing something like turning of recalculation while editing your source data
-------------
This is exactly what is happening. 

I have 2 "dashboard" pages that is referencing the data table and populating this Dashboard_1. Dashboard_2 does the same with different data. The sheet that is being referenced is pretty much a "dump" sheet where I just drop the export data and run the macro to delete the data I don't need.

The only solution I considered was parsing through the data BEFORE putting it into the data table, but haven't had a chance to get around to it. Been pretty busy with so many changes happening at the office.
