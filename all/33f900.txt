large
33f900
Compare two large data sets

I have to download two sets of data from different sources and compare them. There are about 15 different tables that I download as .csv files, and each of them is a different size.

The data _should_ match between them every time, but I have to validate just to be 100% sure.

I was thinking that there have got to be better/easier ways to compare these rather than a bunch of Set1!A1=Set2!A1 type things, or vlookups/matches/that sort of thing.

Something like diff in Unix would be great, but I'm not sure if I can download an equivalent onto my work computer. Also thought of comparing md5 checksums, but also not sure if I could install something to compare them.

Any ideas?


-------------
Power Query can do this...  Also you can directly link power query to where you download the csv files so when you hit refresh-all they are re-downloaded and re-run whatever comparison steps you design
-------------
You can copy and paste into an online diff tool like [diff.so](http://www.diff.so) (disclosure - I am the creator of the site)
-------------
You are already 90%, md5 (or maybe sha1) is the best solution.

Now for the 10% :

* [portable md5](http://getmd5checker.com) to run from usb. It can generate MD5 for single or multiple files.

Just compare the result and you're done.



-------------
Thanks! I'm going to investigate this.
-------------
FYI - there's a built-in diff-like program in windows CLI - fc.exe
-------------
Thanks. Was kind of hoping for some sweet solution in Excel, like Microsoft had something built-in for this kind of thing.

I guess, in a super pinch, I could probably find some VBA code to compute a checksum...just in case I want to :)
-------------
if it looks like something you would use, I could give more of an explanation of how I'd approach your problem.

I'd probably hook up power query to each of the 15 tables.  I'd assign a unique index to each one (like table 1 starts with 1000, table 2 starts with 2000, etc)  then, I'd have to understand the columns you are dealing with.  I think the next step would either be:

1) Append all 15 into one table.  Then within power query (or you can load to a pivot table and do this), you can pivot on a column with your unique value and return the index #'s fromt the 15 tables to the right of the unique value.  If an index column was blank, i'd know there was an issue with one of your data sets

2) Maybe something to do with merging each table (you can pick a left join to return values that don't match, then filter by null to see which values don't match between the tables)  but doing this for all 15 hurts my head at the moment.

Anyways, this is what I love about Power Query...I know theres a way to get your answer, but its gotta be designed and iterated.  Then, when you have it where you like it, you can simply hit refresh all to pull the latest CSV file from wherever you are getting it, it repeats your steps, and you have your answer in seconds.
-------------
hashing may not work, always.......

import them into MySQL server and run compares table vs table.  
Two options - run imports into tables a_TableAName and b_TableBName 
or
create two DB1 and DB2 with same table name sand compare 

Table to table:
http://www.mysqltutorial.org/compare-two-tables-to-find-unmatched-records-mysql.aspx

DB to DB 
http://dev.mysql.com/doc/mysql-utilities/1.5/en/mysqldbcompare.html


-------------
Computing hash of large file(s) in plain vba will takes to long.
-------------
This is really cool, and thank so much for sharing. I can't wait to use this.

However, for my current problem, the best solution turned out to be the built-in command line utility fc.exe. Apparently this thing goes back to MS-DOS days and compares files. 
-------------
OP just want to know are they match or not. Comparing checksum is the best solution.


Comparing table or excel cell by cell is solution if you want to know what is the difference.

-------------
I understand that.  However, having the same "content" and add a space somewhere and your hashes won't match.  Also, they are different files that supposedly contains the same things.  Running a compare will show you where the differences are, if any

-------------
Your solution is good. In my particular situation, the tables SHOULD match identically, so the simpler and faster solution is the checksum. In the very rare (hopefully never) case that we do have to find the differences, the table compare is the way to go I think.
